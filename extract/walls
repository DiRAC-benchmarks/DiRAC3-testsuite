#!/usr/bin/env python
import argparse, csv, re

def main():

    # Parse command line arguments for list of data files and CSV output file
    parser = argparse.ArgumentParser(description="Parse the output of the Walls benchmark for performance metrics")
    parser.add_argument('files', type=argparse.FileType('r'), help='The datafiles to parse', nargs='+')
    parser.add_argument('csv',   type=argparse.FileType('w'), help='The CSV file to write')
    args = parser.parse_args()

    # Regex for parsing data files
    re_dim_proc = r"--- Running Walls in (?P<dims>[0-9]*) dimensions on (?P<procs>[0-9]*) MPI processes[\S\s]*?"
    re_grid     = r"--- Cartesian Grid \[[Gwxyz,]*\] = \[(?P<grid>[0-9,]*)\][\S\s]*?"
    re_mpi      = r"--- MPI Layout     \[[Mwxyz,]*\] = \[(?P<mpi>[0-9,]*)\][\S\s]*?"
    re_cache    = r"--- Cache Block    \[[Bwxyz,]*\] = \[(?P<cache>[0-9,]*)\][\S\s]*?"
    re_time     = r"Time of simulation = (?P<time>[0-9\.]*)[\S\s]*?"
    re_gflops   = r"GFLOP/s = (?P<gflops>[0-9\.]*)[\S\s]*?"
    regex       = re.compile( re_dim_proc + re_grid + re_mpi + re_cache + re_time + re_gflops )

    # Data fields
    fields  = ['Dimensions','MPI Processes','Global Grid','MPI Layout','Cache Block','Time/s','GFlops']
    nfields = len(fields)

    # CSV file writer
    writer = csv.DictWriter(args.csv, fieldnames=fields)
    writer.writeheader()

    # Write from each data file to CSV
    for datafile in args.files:
        data = regex.findall(datafile.read())
        for entries in data:
            writer.writerow({ field : entry for field, entry in zip(fields,entries) })

if __name__ == "__main__":

    main()
